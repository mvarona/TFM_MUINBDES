\capitulo{7}{Conclusiones y Líneas de trabajo futuras}

\section{Conclusiones finales}

A continuación, se presentan las principales conclusiones derivadas de la elaboración de este trabajo.

En primer lugar, el sistema presentado satisface los ocho objetivos marcados inicialmente, aportando una solución innovadora para obtener recomendaciones y perfiles completos de los 8.131 municipios del territorio español. Esta solución se apoya en los sistemas de recomendación basados en contenido y de filtro colaborativo basado en ítems, con lo que la potencial utilidad para los usuarios es grande: Podrán descubrir nuevos lugares en base a sus intereses explícitos, el parecido de un municipio con otro y los intereses de otros usuarios similares. Además, el sistema ha buscado ser escalable, seguro y usable; pilares básicos para el éxito de un sistema que hace uso de Big Data, como se ha aprendido a lo largo de numerosas asignaturas del presente máster. Estas impresiones se derivan también de las evaluaciones cuantitativas y cualitativas llevadas a cabo, donde la satisfacción con el sistema presentado es patente.

A nivel técnico, se desprende una conclusión clara: Para generar un buen sistema de recomendación de filtro colaborativo basado en usuarios es imprescindible tener datos reales del comportamiento de las personas cuyos gustos van a ser modelados. Estos datos deben ser cuanto más numerosos mejor, una de las cualidades del Big Data, ya que será esa cantidad la que permitirá generalizar adecuadamente y encontrar los mejores resultados incluso para usuarios con gustos de nicho o que hayan alimentado poco el sistema. Para ello este trabajo sienta también las bases, recogiendo datos de las valoraciones de los usuarios con el fin de poder utilizarlas para dicho propósito en el futuro.

Por otra parte, se pone de manifiesto el valor de la extracción y procesamiento de datos automáticos, y cómo permiten llevar a cabo comparaciones, visualizaciones de datos o extracción de conocimiento de forma comprensible y abarcable por las personas; algo que sería impensable si no fuera por las técnicas de procesamiento de Big Data existentes.

Por último, se observa cómo las opciones de \textit{Cloud Computing} permiten mucha flexibilidad y constituyen una vía escalable de despliegue de proyectos basados en Big Data, con APIs que permiten tener el control mientras se abstrae la complejidad de la infraestructura subyacente; si bien es cierto que presentan otras desventajas inherentes a esta naturaleza, y cuyos retos han sido también parte del desarrollo de este trabajo.

\section{Líneas futuras}

En cuanto a las líneas de trabajo futuras, se destaca la puesta en producción del sistema, de una manera que sea lo más estable y preparada para el futuro posible. Esto abarca, en primer lugar, la creación de pruebas unitarias y búsqueda de la mayor cobertura de \textit{tests} posible; algo que se puede realizar fácilmente con herramientas como UnitTest \cite{unittest} y Mock \cite{mock}, bibliotecas estándar para la automatización de pruebas en Python, y SonarQube \cite{sonar}, herramienta de análisis estático líder en el mercado con amplia integración con \textit{pipelines} de desarrollo tan conocidos como GitHub, por lo que es ideal para este proyecto.

La idea es incrementar la robustez del sistema confiando en ideas sobradamente probadas en el desarrollo de \textit{software}, como los cuadrantes de testeo ágil (\textit{Agile Testing Quadrants}, \cite{agile_testing_quadrants}) o la pirámide de pruebas; que se basa en la fragilidad y coste de los distintos tipos de pruebas automáticos para distribuir su peso a lo largo del sistema \cite{testing_pyramid}. Con la biblioteca UnitTest para Python y PHPUnit para PHP \cite{PHPUnit} es posible crear pruebas unitarias y de integración, mientras que herramientas como Selenium \cite{selenium}, BrowserStack \cite{browserstack} o Cypress \cite{cypress} permiten llegar a niveles más profundos, como pruebas de \textit{snapshot} (capturas de pantalla) o pruebas punto-a-punto (\textit{end-to-end tests}).

Además, dado que la extracción de datos se realiza combinando datos públicos (vía conjuntos de datos abiertos y APIs públicas) y \textit{Web scraping}, puede ser útil utilizar herramientas de monitorización, como VisualPing \cite{visualping} u otras codificadas de forma personalizada a tal efecto, para ser avisado cuando ocurren cambios significativos que podrían requerir una actualización de los datos o de los \textit{scripts} que los extraen.

Es también importante buscar una forma de automatizar el proceso de extracción. Como se vio en ``Arquitecturas Big Data'', la creación de un \textit{data lake} constituye una de las fases más importantes y que más impacto puede tener en las operaciones de una organización que trabaja con Big Data; ya que permite extraer valor de múltiples maneras de forma constante. A día de hoy, los \textit{scripts} creados para este trabajo deben ser ejecutados en un orden concreto; y sería muy interesante automatizar este proceso para poder ejecutar actualizaciones periódicas de los datos extraídos vía APIs y \textit{Web scraping}, y contar con opciones para incorporar automáticamente también los conjuntos procedentes de datos abiertos y realizar la transformación necesaria para que puedan ser leídos y manejados por el sistema.

Por otra parte, convendría revisar toda la información extraída de Wikipedia, para verificar la exactitud de las informaciones e imágenes cargadas con cada municipio, y asegurarse de que son recursos relevantes y atractivos. Sin embargo, debido a la cantidad de entradas a revisar (8.131 localidades), es una ardua tarea cuyo coste podría ser elevado.

Otro aspecto interesante podría ser aumentar la cantidad de recomendaciones ofrecidas a los usuarios de forma proactiva; por ejemplo, mostrando varios municipios similares al actual si el usuario lo valora positivamente, o varios municipios que le podrían gustar basándose en los gustos de otros usuarios y en los suyos a través del sistema híbrido si valora al actual negativamente, en lugar de mostrar una única recomendación personalizada en cada caso. Para aumentar el atractivo de la funcionalidad, estas recomendaciones adicionales se cargarían con una miniatura del municipio, para lo que, idealmente, cada municipio debería tener una imagen asociada garantizada.

Por último, y dada la importancia del mercado internacional en la búsqueda de municipios españoles donde asentarse \cite{extranjeros_1}, \cite{extranjeros_2}, \cite{extranjeros_3}; la traducción del sitio Web, al menos, al inglés se perfila como una característica imprescindible para poder garantizar la escalabilidad y mejora continua del sistema.